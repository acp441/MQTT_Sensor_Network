{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07e6c4f8",
   "metadata": {},
   "source": [
    "# Feature Engineering für eine Drohnen Fernsteuerung, die mit einem MPU6050 ausgestattet ist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bf9ab5",
   "metadata": {},
   "source": [
    "## 1. Einlesen der Datei und überprüfen, ob die Datenreihen vollständig sind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943f7296",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas.plotting import scatter_matrix as scatmat\n",
    "import os\n",
    "\n",
    "\n",
    "# Absolute Pfad zur Datei extrahieren\n",
    "#ziel_pfad = 'D:\\measurements'\n",
    "ziel_pfad = '../Daten/'\n",
    "\n",
    "# CSV-Datei einlesen\n",
    "data = pd.read_csv(os.path.join(ziel_pfad, 'mpu6050_lennard_run1.csv'), sep=',', decimal='.')\n",
    "data2 = pd.read_csv(os.path.join(ziel_pfad, 'mpu6050_lennard_run2.csv'), sep=',', decimal='.')\n",
    "data = pd.concat([data, data2], ignore_index=True)\n",
    "\n",
    "# Die ersten Zeilen anzeigen\n",
    "data.head()\n",
    "\n",
    "# Informationen über den Datensatz anzeigen\n",
    "data.info()\n",
    "\n",
    "# Sind alle Klassen gleich stark vertreten?\n",
    "data['RuheState'].value_counts()\n",
    "\n",
    "# Gibt es Auffälligkeiten bei der Verteilung der Werte?\n",
    "\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f24ca4",
   "metadata": {},
   "source": [
    "## 2. Irrelevante Merkmale entfernen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c7d3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data.drop(['user', 'gender'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21dacb0",
   "metadata": {},
   "source": [
    "# 3. Visualisierung der Verteilung der numerischen Werte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d463e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "data.hist(bins=50, figsize=(20, 15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6efdd14",
   "metadata": {},
   "source": [
    "## 4. Überprüfen, ob es fehlerhafte Werte gibt (Bspw.: in Spalte 'AccX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0949a27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 300)\n",
    "data['AccX'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefec838",
   "metadata": {},
   "source": [
    "## 5. Fehlerhaften Wert korrigieren (Beispiel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a357a3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.loc[data['z4'] == '-14420-11-2011 04:50:23.713', 'z4'] = -144\n",
    "\n",
    "# Spalte 'z4' in numerischen Typ umwandeln\n",
    "#data['z4'] = pd.to_numeric(data['z4'])\n",
    "\n",
    "# Informationen über den Datensatz erneut anzeigen\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinMaxScaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skalieren\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#data.drop('class', axis=1, inplace=True) # Ist bereits in Schritt 11 erfolgt\n",
    "scaler = MinMaxScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "#print(\"data_scaled.shape:\", data_scaled.shape, \"\\ndata_scaled:\\n\", data_scaled) # uncomment to visualize details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robust Scaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Das ist eine Alternative zum MinMaxScaler, der robust gegenüber auffällig hohen / tiefen Werten ist\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "data_scaled = scaler.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardabweichung berechnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blockgröße für Berechnungen\n",
    "chunk_size = 30\n",
    "\n",
    "data_scaled_pp_df = pd.DataFrame(data_scaled, columns=data.columns)\n",
    "\n",
    "# Anzahl der Blöcke berechnen\n",
    "num_chunks = len(data_scaled_pp_df) // chunk_size\n",
    "\n",
    "# Verarbeitung in Blöcken durchführen\n",
    "processed_data_list = []\n",
    "\n",
    "for i in range(num_chunks):\n",
    "    start_index = i * chunk_size\n",
    "    end_index = (i + 1) * chunk_size\n",
    "\n",
    "    chunk = data_scaled_pp_df.iloc[start_index:end_index, :]\n",
    "\n",
    "    # Standardabweichung für ausgewählte Spalten berechnen\n",
    "    selected_columns = ['AccX', 'AccY', 'AccZ', 'GyroX', 'GyroY', 'GyroZ', 'AngleX', 'AngleY', 'AngleZ', 'AccAngleX', 'AccAngleY']\n",
    "    std_deviation = chunk[selected_columns].std().to_frame().transpose()\n",
    "\n",
    "    # Mittelwert für andere Spalten berechnen\n",
    "    other_columns = ['RuheState', 'FernstState', 'TranspState']\n",
    "    mean_values = chunk[other_columns].mean().to_frame().transpose()\n",
    "\n",
    "    # Neue Daten erstellen\n",
    "    processed_data = pd.concat([std_deviation, mean_values], axis=1)\n",
    "    \n",
    "    processed_data_list.append(processed_data)\n",
    "\n",
    "# Alle berechneten Blöcke zusammenführen\n",
    "result_data = pd.concat(processed_data_list, ignore_index=True)\n",
    "\n",
    "result_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d26230",
   "metadata": {},
   "source": [
    "## 6. Aufteilung des Datensatzes in Trainings- und Validierungsdaten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec47664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aufteilung in Trainings- und Validierungsdatensätze\n",
    "train, val = train_test_split(result_data, test_size=0.1, random_state=42)\n",
    "\n",
    "# Anzahl der Datensätze anzeigen\n",
    "len(train), len(val)\n",
    "\n",
    "# Kopie des Trainingsdatensatzes für Modifikationen\n",
    "data_scaled = train.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24771fd8",
   "metadata": {},
   "source": [
    "## 7. Begrenzung der Auswahl auf die Sensorspalten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90985d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.hist(bins=50, figsize=(20, 15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd1b96a",
   "metadata": {},
   "source": [
    "## 8. Prüfung der Korrelationen für verschiedene Sensoren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196c6d37",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sensors = ['AccX', 'AccY', 'AccZ', 'GyroX', 'GyroY', 'GyroZ', 'AngleX', 'AngleY', 'AngleZ', 'RuheState', 'FernstState', 'TranspState']\n",
    "\n",
    "for sensor_group in [sensors[:3], sensors[3:6], sensors[6:9]]:\n",
    "    scatmat(data[sensor_group], figsize=(15, 10))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f8108b",
   "metadata": {},
   "source": [
    "## 9. Visualisierung der Klassenzuordnung im Scatterplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d48f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gruppiere nach den Klassenattributen und zähle die Anzahl der Vorkommen\n",
    "class_counts = data.groupby(['RuheState', 'FernstState', 'TranspState']).size().reset_index(name='count')\n",
    "\n",
    "# Anzeige aller Kombinationen\n",
    "for i, row in class_counts.iterrows():\n",
    "    print(f\"Klasse {i}: Ruhe={row['RuheState']}, Fernsteuerung={row['FernstState']}, Transport={row['TranspState']} - Anzahl: {row['count']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16c8144",
   "metadata": {},
   "source": [
    "## 10. Scatterplots der unskalierten Daten für verschiedene Sensorpaare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48ffdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle eine temporäre Spalte 'class' basierend auf One-Hot-Encoding\n",
    "data['class'] = data.apply(lambda row: 1 if row['RuheState'] == 1 else (2 if row['FernstState'] == 1 else 3), axis=1)\n",
    "\n",
    "# Visualisiere Scatterplots für jedes Sensor-Paar\n",
    "sensor_pairs = [('AccX', 'AccY'), ('GyroX', 'GyroY'), ('GyroZ', 'AngleX'), ('AngleY', 'AngleZ')]\n",
    "for pair in sensor_pairs:\n",
    "    data.plot(kind=\"scatter\", x=pair[0], y=pair[1], alpha=0.1, c='class', cmap=plt.get_cmap('jet'))\n",
    "    #plt.title(f'Unskalierte Werte - {pair[0]} vs. {pair[1]}')\n",
    "    plt.show()\n",
    "\n",
    "# Entferne die temporäre 'class'-Spalte\n",
    "data.drop('class', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0722d2",
   "metadata": {},
   "source": [
    "## 11. One Hot encoding der Klasse durchführen, wenn noch nicht geschehen (Beispiel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6149f9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "#encoder = OneHotEncoder(categories='auto');\n",
    "#data_label_matrix = data[\"class\"].values.reshape(-1, 1)\n",
    "#data_labels_1hot = encoder.fit_transform(data_label_matrix)\n",
    "#data_labels_1hot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24ea60f",
   "metadata": {},
   "source": [
    "## 14. Skatterplots von Messwertpaaren mit vorheriger Skalierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e154017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skalierte Werte in einem neuen DataFrame mit den ursprünglichen Spaltennamen\n",
    "data_scaled_df = pd.DataFrame(data_scaled, columns=data.columns)\n",
    "\n",
    "\n",
    "# Erstelle eine temporäre Spalte 'class' basierend auf One-Hot-Encoding\n",
    "data_scaled_df['class'] = data_scaled_df.apply(lambda row: 1 if row['RuheState'] == 1 else (2 if row['FernstState'] == 1 else 3), axis=1)\n",
    "\n",
    "\n",
    "# Visualisiere Scatterplots für jedes Sensor-Paar mit den skalierten Werten und den originalen Klassen\n",
    "sensor_pairs = [('AccX', 'AccY'), ('GyroX', 'GyroY'), ('GyroZ', 'AngleX'), ('AngleY', 'AngleZ')]\n",
    "for pair in sensor_pairs:\n",
    "    data_scaled_df.plot(kind=\"scatter\", x=pair[0], y=pair[1], alpha=0.1, c=data_scaled_df['class'], cmap=plt.get_cmap('jet'))\n",
    "    plt.title(f'Skalierte Werte - {pair[0]} vs. {pair[1]}')\n",
    "    plt.show()\n",
    "\n",
    "# Entferne die temporäre 'class'-Spalte\n",
    "#data_scaled_df.drop('class', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "# Annahme: 'data' ist dein ursprüngliches DataFrame mit den Daten\n",
    "\n",
    "# Skalierte Werte in einem neuen DataFrame mit den ursprünglichen Spaltennamen\n",
    "data_scaled_df = pd.DataFrame(data_scaled, columns=data.columns)\n",
    "\n",
    "# Erstelle eine temporäre Spalte 'class' basierend auf One-Hot-Encoding\n",
    "data_scaled_df['class'] = data_scaled_df.apply(lambda row: 1 if row['RuheState'] == 1 else (2 if row['FernstState'] == 1 else 3), axis=1)\n",
    "\n",
    "# Liste aller Labels\n",
    "all_labels = ['AccX', 'AccY', 'AccZ', 'GyroX', 'GyroY', 'GyroZ', 'AngleX', 'AngleY', 'AngleZ', 'RuheState', 'FernstState', 'TranspState']\n",
    "\n",
    "# Erstelle alle möglichen Kombinationen von Label-Paaren\n",
    "label_pairs = list(combinations(all_labels[0:9], 2))\n",
    "print(len(label_pairs))\n",
    "\n",
    "# Anzahl der Zeilen und Spalten für die Subplots\n",
    "num_rows = 9  # Du kannst dies anpassen, um die Anzahl der gewünschten Zeilen zu ändern\n",
    "num_cols = 4  # Du kannst dies anpassen, um die Anzahl der gewünschten Spalten zu ändern\n",
    "\n",
    "# Erstelle Subplots\n",
    "#plt.figure(figsize=(10, 8))\n",
    "fig, axs = plt.subplots(num_rows, num_cols, figsize=(20, 40))\n",
    "\n",
    "# Iteriere durch Label-Paare und erstelle Scatterplots\n",
    "for i in range(num_rows):\n",
    "    for j in range(num_cols):\n",
    "        label_pair = label_pairs[i * num_cols + j]\n",
    "        axs[i, j].scatter(data_scaled_df[label_pair[0]], data_scaled_df[label_pair[1]], alpha=0.1, c=data_scaled_df['class'], cmap=plt.get_cmap('jet'))\n",
    "        axs[i, j].set_title(f'Skalierte Werte - {label_pair[0]} vs. {label_pair[1]}')\n",
    "\n",
    "# Verbessere das Layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15. Vorverarbeitung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16. Training des kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb3155d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "import numpy as np\n",
    "\n",
    "num_features = 14\n",
    "X = np.zeros([len(data_scaled_df), num_features])\n",
    "y = data_scaled_df['class']\n",
    "\n",
    "k = 5\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "features = data_scaled_df.drop(columns='RuheState').drop(columns='class').drop(columns='TranspState').drop(columns='FernstState')\n",
    "clf.fit(features, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 17. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction mit Test-Array\n",
    "y_predict = clf.predict(features)\n",
    "\n",
    "acc = np.mean(y_predict == (data_scaled_df['class']).astype(int).values)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction mit Validation-Array\n",
    "\n",
    "# Skalierte Werte in einem neuen DataFrame mit den ursprünglichen Spaltennamen\n",
    "val_df = pd.DataFrame(val, columns=data.columns)\n",
    "\n",
    "# Erstelle eine temporäre Spalte 'class' basierend auf One-Hot-Encoding\n",
    "val_df['class'] = val_df.apply(lambda row: 1 if row['RuheState'] == 1 else (2 if row['FernstState'] == 1 else 3), axis=1)\n",
    "\n",
    "val_labels = val_df['class']\n",
    "val_data = val_df.drop(columns='RuheState').drop(columns='class').drop(columns='TranspState').drop(columns='FernstState')\n",
    "\n",
    "# Prediction\n",
    "prediction = clf.predict(val_data)\n",
    "\n",
    "acc = np.mean(prediction == val_labels.astype(int).values)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python MQTT Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "live_data = {'AccX' :[],\n",
    "        'AccY' : [],\n",
    "        'AccZ' : [],\n",
    "        'GyroX' : [],\n",
    "        'GyroY' : [],\n",
    "        'GyroZ' : [],\n",
    "        'AngleX' : [],\n",
    "        'AngleY' : [],\n",
    "        'AngleZ' : [],\n",
    "        'AccAngleX' : [],\n",
    "        'AccAngleY' : [],     \n",
    "        'RuheState' : 0,\n",
    "        'FernstState' : 0,\n",
    "        'TranspState' : 0,}\n",
    "\n",
    "live_data_df = pd.DataFrame(live_data)\n",
    "\n",
    "\n",
    "live_data_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MQTT Live-Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paho.mqtt.client as mqtt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "live_data_df = pd.DataFrame(live_data)\n",
    "\n",
    "# The callback for when the client receives a CONNACK response from the server.\n",
    "def on_connect(client, userdata, flags, rc):\n",
    "    print(\"Connected with result code \"+str(rc))\n",
    "\n",
    "    # Subscribing in on_connect() means that if we lose the connection and\n",
    "    # reconnect then subscriptions will be renewed.\n",
    "    # client.subscribe(\"$SYS/#\")\n",
    "\n",
    "# The callback for when a PUBLISH message is received from the server.\n",
    "counter = 0 # counts how many times angleZ is received \n",
    "\n",
    "def on_message(client, userdata, msg):\n",
    "    # print(msg.topic+\" \"+str(msg.payload))\n",
    "    global accX, accY, accZ, gyroX, gyroY, gyroZ, angleX, angleY, angleZ, accAngleX, accAngleY, live_data_df\n",
    "    global counter\n",
    "    if(msg.topic == 'accelerationX'):\n",
    "        accX = msg.payload.decode('UTF-8')\n",
    "        #print(accX)\n",
    "    elif(msg.topic == 'accelerationY'):\n",
    "        accY = msg.payload.decode('UTF-8')\n",
    "        #print(accY)\n",
    "    elif(msg.topic == 'accelerationZ'):\n",
    "        accZ = msg.payload.decode('UTF-8')\n",
    "    \n",
    "    elif(msg.topic == 'gyrometerX'):\n",
    "        gyroX = msg.payload.decode('UTF-8')\n",
    "    elif(msg.topic == 'gyrometerY'):\n",
    "        gyroY = msg.payload.decode('UTF-8')\n",
    "    elif(msg.topic == 'gyrometerZ'):\n",
    "        gyroZ = msg.payload.decode('UTF-8')\n",
    "\n",
    "    elif(msg.topic == 'angleX'):\n",
    "        angleX = msg.payload.decode('UTF-8')\n",
    "    elif(msg.topic == 'angleY'):\n",
    "        angleY = msg.payload.decode('UTF-8')\n",
    "    elif(msg.topic == 'angleZ'):\n",
    "        angleZ = msg.payload.decode('UTF-8')\n",
    "    elif(msg.topic == 'accAngleX'):\n",
    "        accAngleX = msg.payload.decode('UTF-8')\n",
    "    elif(msg.topic == 'accAngleY'):\n",
    "        accAngleY = msg.payload.decode('UTF-8')\n",
    "        counter += 1\n",
    "\n",
    "        new_row = {\n",
    "        'AccX' :[accX],\n",
    "        'AccY' : [accY],\n",
    "        'AccZ' : [accZ],\n",
    "        'GyroX' : [gyroX],\n",
    "        'GyroY' : [gyroY],\n",
    "        'GyroZ' : [gyroZ],\n",
    "        'AngleX' : [angleX],\n",
    "        'AngleY' : [angleY],\n",
    "        'AngleZ' : [angleZ],\n",
    "        'AccAngleX' : [accAngleX],\n",
    "        'AccAngleY' : [accAngleY],\n",
    "        'RuheState' : 0,\n",
    "        'FernstState' : 0,\n",
    "        'TranspState' : 0,\n",
    "        }\n",
    "        \n",
    "        # convert new Data to DataFrame\n",
    "        new_row = pd.DataFrame(new_row)\n",
    "\n",
    "        # append new row to live_data_df\n",
    "        live_data_df = pd.concat([new_row, live_data_df], ignore_index=True)\n",
    "\n",
    "        # after 30 measurements, call the classifier\n",
    "        if counter == 10:\n",
    "            counter = 0\n",
    "            live_data_scaled = pd.DataFrame(scaler.transform(live_data_df), columns=data.columns)   # scaling our data\n",
    "            live_data_features = live_data_scaled.drop(columns='RuheState').drop(columns='TranspState').drop(columns='FernstState')\n",
    "            # live_data_features = live_data_scaled[['AccY', 'GyroX']]\n",
    "\n",
    "            std_df = live_data_features[selected_columns].std().to_frame().transpose()\n",
    "            #print(std_df)\n",
    "\n",
    "            #std_df = pd.DataFrame([['AccY', 'GyroX'], [std_accy, std_gyrox]])\n",
    "\n",
    "            live_predict = clf.predict(std_df)\n",
    "            print('Prediction: ', str(live_predict.mean()))\n",
    "            if round(live_predict.mean()) == 1:\n",
    "                print('Ruhe') \n",
    "            elif round(live_predict.mean()) == 2:\n",
    "                print('Fernsteuerung') \n",
    "            elif round(live_predict.mean()) == 3:\n",
    "                print('Transport')\n",
    "\n",
    "\n",
    "            # Plotting \n",
    "            plt.figure(figsize=(10, 7))\n",
    "            plt.scatter(train['AccY'], train['GyroX'],marker=\".\", alpha=0.3, c=data_scaled_df['class'], cmap=plt.get_cmap('rainbow'))\n",
    "            plt.scatter(std_df['AccY'], std_df['GyroX'], marker=\"P\", alpha=0.9, c=4, cmap=plt.get_cmap('jet'))\n",
    "            #print(live_data_features)\n",
    "            # axes = plt.gca()\n",
    "            # axes.set_xlim([-5, 5])\n",
    "            # axes.set_ylim([-20, 20])\n",
    "\n",
    "            ## ACHTUNG: Glaube die Labels der Prediction passen nicht zu den Features. Im Plot sind falsche Farben in falschen Bereichen zu erkennen\n",
    "\n",
    "            # Verbessere das Layout\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            clear_output(wait=True)\n",
    "\n",
    "            # Reset live_predict and live_data_df\n",
    "            live_predict = None\n",
    "            live_data_df = live_data_df.head(20) # keep 20 rows of the currenct frame\n",
    "\n",
    "    \n",
    "\n",
    "client = mqtt.Client()\n",
    "client.on_connect = on_connect\n",
    "client.on_message = on_message\n",
    "\n",
    "client.connect(\"192.168.137.1\", 1883, 60)\n",
    "client.subscribe(\"ESP_message\", 0)\n",
    "client.subscribe(\"accelerationX\", 0)\n",
    "client.subscribe(\"accelerationY\", 0)\n",
    "client.subscribe(\"accelerationZ\", 0)\n",
    "client.subscribe(\"gyrometerX\", 0)\n",
    "client.subscribe(\"gyrometerY\", 0)\n",
    "client.subscribe(\"gyrometerZ\", 0)\n",
    "client.subscribe(\"angleX\", 0)\n",
    "client.subscribe(\"angleY\", 0)\n",
    "client.subscribe(\"angleZ\", 0)\n",
    "client.subscribe(\"accAngleX\", 0)\n",
    "client.subscribe(\"accAngleY\", 0)\n",
    "\n",
    "\n",
    "# Blocking call that processes network traffic, dispatches callbacks and\n",
    "# handles reconnecting.\n",
    "# Other loop*() functions are available that give a threaded interface and a\n",
    "# manual interface.\n",
    "client.loop_forever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardabweichung\n",
    "\n",
    "data_features = data[['AccY', 'GyroX']]\n",
    "\n",
    "std_accy = data_features[['AccY']].std()\n",
    "std_gyrox = data_features[['GyroX']].std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 1, 100)\n",
    "X0, X1 = np.meshgrid(x, x)\n",
    "Xstack = np.dstack((X0, X1))\n",
    "Y = np.zeros(X0.shape)\n",
    "for r in range(100):\n",
    "    for c in range(100):\n",
    "        Y[r, c] = clf.predict(Xstack[r, c, :].reshape(1, -1))\n",
    "\n",
    "plt.contourf(X0, X1, Y, cmap=plt.get_cmap('jet'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ansatz Classifier nur mit Acc Y und Gyro X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "num_features = 14\n",
    "labels = data_scaled_df['class']\n",
    "\n",
    "k = 5\n",
    "clf = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "features = data_scaled_df[['AccY', 'GyroX']]\n",
    "clf.fit(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "\n",
    "val_labels = val_df['class']\n",
    "val_features = val_df[['AccY', 'GyroX']]\n",
    "\n",
    "# Prediction\n",
    "prediction = clf.predict(val_features)\n",
    "\n",
    "acc = np.mean(prediction == val_labels.astype(int).values)\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def confusion_matrix(results, labels):\n",
    "    data = {'y_Actual': results.astype(np.uint8), 'y_Predicted': labels}\n",
    "    df = pd.DataFrame(data, columns=['y_Actual', 'y_Predicted'])\n",
    "    cm = pd.crosstab(df['y_Actual'], df['y_Predicted'])\n",
    "    cm = cm.astype(np.float32) / cm.sum(axis=1).values[:, np.newaxis] * 100.0\n",
    "    sns.heatmap(cm, annot=True, fmt='.1f', annot_kws={\"size\": 8})\n",
    "    plt.title('Normalized Confusion Matrix in %')\n",
    "    plt.show()\n",
    "\n",
    "confusion_matrix(prediction, val_labels.astype(int).values) # val confusion Matrix\n",
    "confusion_matrix(y_predict, (data_scaled_df['class']).astype(int).values)   # train confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix mit verarbeiteten Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix mit verarbeiteten Daten\n",
    "\n",
    "confusion_matrix(prediction, val_labels.astype(int).values) \n",
    "confusion_matrix(y_predict, (data_scaled_df['class']).astype(int).values)   # train confusion Matrix"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
